{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity DEND Project-3: AWS Set-up\n",
    "### IaC set-up for Project-3 AWS Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /Users/sathwikmaddi/.local/lib/python3.9/site-packages (2.9.7)\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# STEP 0: Make sure you have an AWS secret and access key\n",
    "\n",
    "- Create a new IAM user in your AWS account\n",
    "- Give it `AdministratorAccess`, From `Attach existing policies directly` Tab\n",
    "- Take note of the access key and secret \n",
    "- Edit the file `dwh.cfg` in the same folder as this notebook and fill\n",
    "<font color='red'>\n",
    "<BR>\n",
    "[AWS]<BR>\n",
    "KEY= YOUR_AWS_KEY<BR>\n",
    "SECRET= YOUR_AWS_SECRET<BR>\n",
    "<font/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DWH Params from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>redshift-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>redshift-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>redshift_role</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param             Value\n",
       "0        DWH_CLUSTER_TYPE        multi-node\n",
       "1           DWH_NUM_NODES                 4\n",
       "2           DWH_NODE_TYPE         dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER  redshift-cluster\n",
       "4                  DWH_DB  redshift-cluster\n",
       "5             DWH_DB_USER               dev\n",
       "6         DWH_DB_PASSWORD          Passw0rd\n",
       "7                DWH_PORT              5439\n",
       "8       DWH_IAM_ROLE_NAME     redshift_role"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "# NOTE: Un-comment this to print the result.\n",
    "pd.DataFrame({\"Param\":\n",
    "                 [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "             \"Value\":\n",
    "                 [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clients for EC2, S3, IAM, and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "ec2 = boto3.resource(   'ec2', \n",
    "                      region_name=\"us-west-2\",\n",
    "                      aws_access_key_id=KEY,\n",
    "                      aws_secret_access_key=SECRET)\n",
    "\n",
    "s3 = boto3.resource(  's3',\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET)\n",
    "\n",
    "iam = boto3.client('iam',\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET)\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                        region_name=\"us-west-2\",\n",
    "                        aws_access_key_id=KEY,\n",
    "                        aws_secret_access_key=SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out the sample data sources on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-01-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-02-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-03-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-04-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-05-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-06-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-07-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-08-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-09-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-10-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-11-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-12-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-13-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-14-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-15-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-16-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-17-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-18-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-19-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-20-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-21-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-22-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-23-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-24-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-25-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-26-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-27-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-28-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-29-events.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='log_data/2018-11-30-events.json')\n",
      "COUNT: 30\n"
     ]
    }
   ],
   "source": [
    "LOG_DATA      = config.get(\"S3\", \"BUCKET\")\n",
    "logDataBucket = s3.Bucket(LOG_DATA)\n",
    "count = 0\n",
    "\n",
    "# Iterate over log_data bucket objects and print\n",
    "for object in logDataBucket.objects.filter(Prefix='log_data'):\n",
    "    count += 1\n",
    "    print(object)\n",
    "print(\"COUNT: \" + str(count))\n",
    "# => COUNT: 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "size = sum(1 for _ in logDataBucket.objects.filter(Prefix='log_data'))\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAAAW128F429D538.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAABD128F429CF47.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAADZ128F9348C2E.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAAEF128F4273421.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAAFD128F92F423A.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAAMO128F1481E7F.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAAMQ128F1460CD3.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAAPK128E0786D96.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAARJ128F9320760.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAAVG12903CFA543.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/A/TRAAAVO128F93133D4.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABCL128F4286650.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABDL12903CAABBA.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABJL12903CDCF1A.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABJV128F1460C49.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABLR128F423B7E3.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABNV128F425CEE1.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABRB128F9306DD5.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABVM128F92CA9DC.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABXG128F9318EBD.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABYN12903CFD305.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/B/TRAABYW128F4244559.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACCG128F92E8A55.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACER128F4290F96.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACFV128F935E50B.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACHN128F1489601.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACIW12903CC0F6D.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACLV128F427E123.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACNS128F14A2DF5.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACOW128F933E35F.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACPE128F421C1B9.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACQT128F9331780.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACSL128F93462F4.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACTB12903CAAF15.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACVS128E078BE39.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/A/C/TRAACZK128F4243829.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABACN128F425B784.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAFJ128F42AF24E.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAFP128F931E9A1.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAIO128F42938F9.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABATO128F42627E9.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAVQ12903CBF7E0.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAWW128F4250A31.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAXL128F424FC50.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAXR128F426515F.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAXV128F92F6AE3.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/A/TRABAZH128F930419A.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBAM128F429D223.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBBV128F42967D7.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBJE12903CDB442.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBKX128F4285205.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBLU128F93349CF.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBNP128F932546F.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBOP128F931B50D.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBOR128F4286200.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBTA128F933D304.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBVJ128F92F7EAA.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBXU128F92FEF48.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/B/TRABBZN12903CD9297.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCAJ12903CDFCC2.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCEC128F426456E.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCEI128F424C983.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCFL128F149BB0D.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCIX128F4265903.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCKL128F423A778.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCPZ128F4275C32.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCRU128F423F449.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCTK128F934B224.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCUQ128E0783E2B.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCXB128F4286BD3.json')\n",
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='song_data/A/B/C/TRABCYE128F934CE1D.json')\n",
      "COUNT: 71\n"
     ]
    }
   ],
   "source": [
    "SONG_DATA      = config.get(\"S3\", \"BUCKET\")\n",
    "songDataBucket = s3.Bucket(SONG_DATA)\n",
    "count = 0\n",
    "\n",
    "# Iterate over song_data bucket objects and print\n",
    "for object in songDataBucket.objects.filter(Prefix='song_data'):\n",
    "    count += 1\n",
    "    print(object)\n",
    "print(\"COUNT: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='temporary-sathwik', key='songs_json_paths.json')\n",
      "COUNT: 1\n"
     ]
    }
   ],
   "source": [
    "SONG_DATA      = config.get(\"S3\", \"BUCKET\")\n",
    "songDataBucket = s3.Bucket(SONG_DATA)\n",
    "count = 0\n",
    "\n",
    "# Iterate over song_data bucket objects and print\n",
    "for object in songDataBucket.objects.filter(Prefix='songs_json'):\n",
    "    count += 1\n",
    "    print(object)\n",
    "print(\"COUNT: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary-sathwik\n",
      "'s3://temporary-sathwik/songs_json_path.json'\n"
     ]
    }
   ],
   "source": [
    "LOG_DATA      = config.get(\"S3\", \"BUCKET\")\n",
    "LOCAL_PATH    = config.get(\"S3\", \"LOCAL_PATH\")\n",
    "SONGS_JSONPATH = config.get(\"S3\", \"SONGS_JSONPATH\")\n",
    "print(LOG_DATA)\n",
    "print(SONGS_JSONPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## STEP 1: IAM ROLE\n",
    "- Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name redshift_role already exists.\n"
     ]
    }
   ],
   "source": [
    "# Create the IAM role (if not exists)\n",
    "\n",
    "try:\n",
    "    print('1.1 Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description=\"Allow Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "                'Effect': 'Allow',\n",
    "                'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "            'Version': '2012-10-17'})\n",
    "    )\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 Attaching Policy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach Policy\n",
    "\n",
    "print('1.2 Attaching Policy')\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                      PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::354280233834:role/redshift_role\n"
     ]
    }
   ],
   "source": [
    "# Get and print the IAM role ARN\n",
    "print('1.3 Get the IAM role ARN')\n",
    "iam_role = iam.get_role(\n",
    "                        RoleName=DWH_IAM_ROLE_NAME\n",
    "                        )\n",
    "roleArn = iam_role['Role']['Arn']\n",
    "# NOTE: Un-comment this to print the result.\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2:  Redshift Cluster\n",
    "\n",
    "- Create a RedShift Cluster\n",
    "- For complete arguments to `create_cluster`, see [docs](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html#Redshift.Client.create_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster( \n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        IamRoles=[roleArn]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.1 *Describe* the cluster to see its status\n",
    "- run this block several times until the cluster status becomes `Available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>redshift-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>redshift-cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'redshift-cluster.c9irqexzniz5.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-056f292b4663a579e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1           NodeType   \n",
       "2      ClusterStatus   \n",
       "3     MasterUsername   \n",
       "4             DBName   \n",
       "5           Endpoint   \n",
       "6              VpcId   \n",
       "7      NumberOfNodes   \n",
       "\n",
       "                                                                                         Value  \n",
       "0                                                                             redshift-cluster  \n",
       "1                                                                                    dc2.large  \n",
       "2                                                                                    available  \n",
       "3                                                                                          dev  \n",
       "4                                                                             redshift-cluster  \n",
       "5  {'Address': 'redshift-cluster.c9irqexzniz5.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6                                                                        vpc-056f292b4663a579e  \n",
       "7                                                                                            4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "# NOTE: Un-comment this to print the result.\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "<h2> 2.2 Take note of the cluster <font color='red'> endpoint and role ARN </font> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>DO NOT RUN THIS unless the cluster status becomes \"Available\" </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  redshift-cluster.c9irqexzniz5.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::354280233834:role/redshift_role\n"
     ]
    }
   ],
   "source": [
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Open an incoming  TCP port to access the cluster endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-0852bdada106e19f2')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    \n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName= defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP', \n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Make sure you can connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n",
      "Requirement already satisfied: psycopg2-binary in /Users/sathwikmaddi/.local/lib/python3.9/site-packages (2.9.7)\n",
      "/Users/sathwikmaddi/opt/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "!pip install --upgrade psycopg2-binary\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<connection object at 0x7f93680b22e0; dsn: 'user=dev password=xxx dbname=redshift-cluster host=redshift-cluster.c9irqexzniz5.us-west-2.redshift.amazonaws.com port=5439', closed: 0>\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn_string = \"dbname='{}' port='{}' user='{}' password='{}' host='{}'\".format(DWH_DB, DWH_PORT, DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT)\n",
    "\n",
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Test COPIED and INSERTED data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Query staging tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1260358806.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/fd/drxrvjb94_d8v1kkgxzpx0n40000gn/T/ipykernel_82476/1260358806.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    SELECT COUNT(*)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Number of items in staging_events table\n",
    "%%time\n",
    "%%sql\n",
    "SELECT COUNT(*)\n",
    "FROM staging_events;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items in staging_songs table\n",
    "%%time\n",
    "%%sql\n",
    "SELECT COUNT(*)\n",
    "FROM staging_songs;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Query Analysis tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2724355246.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/fd/drxrvjb94_d8v1kkgxzpx0n40000gn/T/ipykernel_82476/2724355246.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    SELECT COUNT(*)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Number of items in users table\n",
    "%%time\n",
    "%%sql\n",
    "SELECT COUNT(*)\n",
    "FROM users;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items in songs table\n",
    "%%time\n",
    "%%sql\n",
    "SELECT COUNT(*)\n",
    "FROM songs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items in artists table\n",
    "%%time\n",
    "%%sql\n",
    "SELECT COUNT(*)\n",
    "FROM artists;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items in time table\n",
    "%%time\n",
    "%%sql\n",
    "SELECT COUNT(*)\n",
    "FROM time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items in songplay table\n",
    "%%time\n",
    "%%sql\n",
    "SELECT COUNT(*)\n",
    "FROM songplays;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to answer a question: Who played which song and when.\n",
    "%%time\n",
    "%%sql\n",
    "SELECT  sp.songplay_id,\n",
    "        u.user_id,\n",
    "        u.last_name,\n",
    "        u.first_name,\n",
    "        sp.start_time,\n",
    "        a.name,\n",
    "        s.title\n",
    "FROM songplays AS sp\n",
    "        JOIN users   AS u ON (u.user_id = sp.user_id)\n",
    "        JOIN songs   AS s ON (s.song_id = sp.song_id)\n",
    "        JOIN artists AS a ON (a.artist_id = sp.artist_id)\n",
    "        JOIN time    AS t ON (t.start_time = sp.start_time)\n",
    "ORDER BY (u.last_name)\n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: Clean up your resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>DO NOT RUN THIS UNLESS YOU ARE SURE <br/> \n",
    "    We will be using these resources in the next exercises</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "#redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run this block several times until the cluster really deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "# NOTE: Un-comment this to print the result.\n",
    "#prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "#iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "#iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)\n",
    "#### CAREFUL!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
